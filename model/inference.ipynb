{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a274ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9f2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model for performance_score\n",
      "No label encoder for performance_score (regression model)\n",
      "Loaded model for burnout_risk_score\n",
      "Loaded label encoder for burnout_risk_score\n",
      "All models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the feature scaler\n",
    "scaler = joblib.load(\"feature_scaler.pkl\")\n",
    "\n",
    "# Define target columns (same as in training)\n",
    "target_cols = [\n",
    "    \"performance_score\",\n",
    "    \"burnout_risk_score\"\n",
    "]\n",
    "\n",
    "# Load models\n",
    "models = {}\n",
    "label_encoders = {}\n",
    "\n",
    "for target in target_cols:\n",
    "    model_path = f\"model_{target}.pkl\"\n",
    "    models[target] = joblib.load(model_path)\n",
    "    print(f\"Loaded model for {target}\")\n",
    "\n",
    "    # Try to load label encoder if it exists (for classification models)\n",
    "    try:\n",
    "        le_path = f\"label_encoder_{target}.pkl\"\n",
    "        label_encoders[target] = joblib.load(le_path)\n",
    "        print(f\"Loaded label encoder for {target}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No label encoder for {target} (regression model)\")\n",
    "\n",
    "print(\"All models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c612618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_employee_metrics(employee_data):\n",
    "    \"\"\"\n",
    "    Make predictions for employee metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    employee_data : pd.DataFrame or dict\n",
    "        Employee features. Should contain all feature columns used during training.\n",
    "        Can be a single row or multiple rows.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Predictions for all target metrics\n",
    "    \"\"\"\n",
    "    # Convert dict to DataFrame if needed\n",
    "    if isinstance(employee_data, dict):\n",
    "        employee_data = pd.DataFrame([employee_data])\n",
    "\n",
    "    # Make a copy to avoid modifying original data\n",
    "    data = employee_data.copy()\n",
    "\n",
    "    # Drop target columns if they exist in the input\n",
    "    data = data.drop(columns=[col for col in target_cols if col in data.columns], errors='ignore')\n",
    "\n",
    "    # Scale the features\n",
    "    X_scaled = scaler.transform(data)\n",
    "\n",
    "    # Make predictions for each target\n",
    "    predictions = {}\n",
    "\n",
    "    for target in target_cols:\n",
    "        model = models[target]\n",
    "        pred = model.predict(X_scaled)\n",
    "\n",
    "        # If classification model, decode the predictions\n",
    "        if target in label_encoders:\n",
    "            pred = label_encoders[target].inverse_transform(pred.astype(int))\n",
    "            predictions[target] = pred\n",
    "\n",
    "            # Also get probability predictions if available\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                proba = model.predict_proba(X_scaled)\n",
    "                # Store max probability as confidence\n",
    "                predictions[f\"{target}_confidence\"] = proba.max(axis=1)\n",
    "        else:\n",
    "            # Regression model\n",
    "            predictions[target] = pred\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame(predictions)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1008fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for sample employee:\n",
      "   performance_score burnout_risk_score  burnout_risk_score_confidence\n",
      "0           0.635363             medium                       0.987776\n"
     ]
    }
   ],
   "source": [
    "# Create sample employee data\n",
    "sample_employee = {\n",
    "    'meeting_hours_per_week': 9.5,\n",
    "    'meeting_counts_per_week': 11,\n",
    "    'messages_sent_per_day': 93,\n",
    "    'messages_received_per_day': 133,\n",
    "    'avg_response_latency_min': 9.6,\n",
    "    'communication_burstiness': 0.37,\n",
    "    'after_hours_message_ratio': 0.201,\n",
    "    'communication_balance': 0.69,\n",
    "    'conversation_length_avg': 12.2,\n",
    "    'avg_tasks_assigned_per_week': 19,\n",
    "    'avg_tasks_completed_per_week': 14,\n",
    "    'task_completion_rate': 0.72,\n",
    "    'avg_task_age_days': 8.3,\n",
    "    'overdue_task_ratio': 0.29,\n",
    "    'task_comment_sentiment_mean': 0.04,\n",
    "    'logged_hours_per_week': 43.4,\n",
    "    'variance_in_work_hours': 1.04,\n",
    "    'late_start_count_per_month': 5,\n",
    "    'early_exit_count_per_month': 0,\n",
    "    'absenteeism_rate': 0.044,\n",
    "    'avg_break_length_minutes': 59.0\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "predictions = predict_employee_metrics(sample_employee)\n",
    "print(\"Predictions for sample employee:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5974265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Predictions (showing first 5 rows):\n",
      "   performance_score  performance_score burnout_risk_score burnout_risk_score  \\\n",
      "0               0.64           0.635363               0.38             medium   \n",
      "1               0.75           0.747491               0.30                low   \n",
      "2               0.70           0.709440               0.41             medium   \n",
      "3               0.72           0.718327               0.53             medium   \n",
      "4               0.67           0.670477               0.31                low   \n",
      "\n",
      "   performance_score  performance_score burnout_risk_score burnout_risk_score  \\\n",
      "0               0.64           0.635363               0.38             medium   \n",
      "1               0.75           0.747491               0.30                low   \n",
      "2               0.70           0.709440               0.41             medium   \n",
      "3               0.72           0.718327               0.53             medium   \n",
      "4               0.67           0.670477               0.31                low   \n",
      "\n",
      "   burnout_risk_score_confidence  \n",
      "0                       0.987776  \n",
      "1                       0.972934  \n",
      "2                       0.953780  \n",
      "3                       0.997702  \n",
      "4                       0.974750  \n"
     ]
    }
   ],
   "source": [
    "# Load test data (using a few rows from the training dataset as example)\n",
    "test_data = pd.read_csv(\"dataset/employee_data.csv\").head(5)\n",
    "\n",
    "# Make predictions on batch\n",
    "batch_predictions = predict_employee_metrics(test_data)\n",
    "\n",
    "# Combine with original features for comparison\n",
    "results = pd.concat([\n",
    "    test_data.reset_index(drop=True),\n",
    "    batch_predictions\n",
    "], axis=1)\n",
    "\n",
    "print(\"\\nBatch Predictions (showing first 5 rows):\")\n",
    "print(results[['performance_score', 'burnout_risk_score'] + list(batch_predictions.columns)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42303b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Employee 1 Analysis:\n",
      "============================================================\n",
      "ðŸ“Š Performance Score: 0.64\n",
      "   âš ï¸  Average performance - meeting expectations\n",
      "ðŸ”¥ Burnout Risk: medium\n",
      "   Confidence: 98.78%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def interpret_predictions(predictions_df, employee_id=None):\n",
    "    \"\"\"\n",
    "    Provide human-readable interpretation of predictions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions_df : pd.DataFrame\n",
    "        DataFrame with predictions\n",
    "    employee_id : int, optional\n",
    "        Index of specific employee to interpret (default: all)\n",
    "    \"\"\"\n",
    "    if employee_id is not None:\n",
    "        predictions_df = predictions_df.iloc[[employee_id]]\n",
    "\n",
    "    for idx, row in predictions_df.iterrows():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Employee {idx + 1} Analysis:\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Performance Score\n",
    "        if 'performance_score' in row:\n",
    "            perf = row['performance_score']\n",
    "            if isinstance(perf, (int, float)):\n",
    "                print(f\"ðŸ“Š Performance Score: {perf:.2f}\")\n",
    "                if perf >= 0.7:\n",
    "                    print(\"   âœ… High performance - exceeding expectations\")\n",
    "                elif perf >= 0.5:\n",
    "                    print(\"   âš ï¸  Average performance - meeting expectations\")\n",
    "                else:\n",
    "                    print(\"   âš ï¸  Below average - may need support\")\n",
    "            else:\n",
    "                print(f\"ðŸ“Š Performance Score: {perf}\")\n",
    "                if 'performance_score_confidence' in row:\n",
    "                    print(f\"   Confidence: {row['performance_score_confidence']:.2%}\")\n",
    "\n",
    "        # Burnout Risk\n",
    "        if 'burnout_risk_score' in row:\n",
    "            burnout = row['burnout_risk_score']\n",
    "            if isinstance(burnout, (int, float)):\n",
    "                print(f\"ðŸ”¥ Burnout Risk: {burnout:.2f}\")\n",
    "                if burnout >= 0.6:\n",
    "                    print(\"   ðŸš¨ HIGH RISK - Immediate intervention recommended\")\n",
    "                elif burnout >= 0.4:\n",
    "                    print(\"   âš ï¸  MODERATE RISK - Monitor closely and provide support\")\n",
    "                else:\n",
    "                    print(\"   âœ… LOW RISK - Employee wellbeing appears healthy\")\n",
    "            else:\n",
    "                print(f\"ðŸ”¥ Burnout Risk: {burnout}\")\n",
    "                if 'burnout_risk_score_confidence' in row:\n",
    "                    print(f\"   Confidence: {row['burnout_risk_score_confidence']:.2%}\")\n",
    "\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "# Interpret the sample prediction\n",
    "interpret_predictions(predictions, employee_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede1fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response:\n",
      "{'predictions': {'performance_score': 0.6353628635406494, 'burnout_risk_score': 'medium', 'burnout_risk_score_confidence': 0.9877759218215942}, 'interpretations': {'performance': 'average', 'burnout_level': 'medium'}, 'status': 'success'}\n"
     ]
    }
   ],
   "source": [
    "def get_employee_predictions_api(employee_features):\n",
    "    \"\"\"\n",
    "    API-ready function that returns predictions as a JSON-serializable dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    employee_features : dict\n",
    "        Dictionary containing employee feature values\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Predictions and interpretations in JSON format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make predictions\n",
    "        predictions = predict_employee_metrics(employee_features)\n",
    "\n",
    "        # Convert to dictionary\n",
    "        result = {}\n",
    "\n",
    "        for col in predictions.columns:\n",
    "            val = predictions[col].iloc[0]\n",
    "            # Convert numpy types to Python types for JSON serialization\n",
    "            if isinstance(val, (np.integer, np.floating)):\n",
    "                result[col] = float(val)\n",
    "            else:\n",
    "                result[col] = str(val)\n",
    "\n",
    "        # Add interpretations\n",
    "        interpretations = {}\n",
    "\n",
    "        # Performance interpretation\n",
    "        if 'performance_score' in result:\n",
    "            perf = result['performance_score']\n",
    "            if isinstance(perf, float):\n",
    "                if perf >= 0.7:\n",
    "                    interpretations['performance'] = 'high'\n",
    "                elif perf >= 0.5:\n",
    "                    interpretations['performance'] = 'average'\n",
    "                else:\n",
    "                    interpretations['performance'] = 'low'\n",
    "            else:\n",
    "                interpretations['performance'] = perf\n",
    "\n",
    "        # Burnout interpretation\n",
    "        if 'burnout_risk_score' in result:\n",
    "            burnout = result['burnout_risk_score']\n",
    "            if isinstance(burnout, float):\n",
    "                if burnout >= 0.6:\n",
    "                    interpretations['burnout_level'] = 'high'\n",
    "                elif burnout >= 0.4:\n",
    "                    interpretations['burnout_level'] = 'moderate'\n",
    "                else:\n",
    "                    interpretations['burnout_level'] = 'low'\n",
    "            else:\n",
    "                interpretations['burnout_level'] = burnout\n",
    "\n",
    "        return {\n",
    "            'predictions': result,\n",
    "            'interpretations': interpretations,\n",
    "            'status': 'success'\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'message': str(e)\n",
    "        }\n",
    "\n",
    "# Test the API function\n",
    "api_result = get_employee_predictions_api(sample_employee)\n",
    "print(\"API Response:\")\n",
    "print(api_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e748b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save predictions\n",
    "# results.to_csv(\"employee_predictions.csv\", index=False)\n",
    "# print(\"Predictions saved to employee_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
